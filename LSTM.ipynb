{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc538528-5c94-4562-93c6-9edd69072ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35586c7-3640-45fc-b45e-6751ea16e2f3",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70dc39d8-a815-41e5-8149-08bb84845c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('preprocessed_train.csv')\n",
    "test_df = pd.read_csv('preprocessed_test.csv')\n",
    "val_df = pd.read_csv('preprocessed_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81345f18-d03e-4334-a848-533461a10a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fuck bayless isoing</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make feel threatened</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dirty southern wanker</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>omg peyton good enough help u playoff dumbass ...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>need board create bit space name we’ll good</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0                                fuck bayless isoing     anger\n",
       "1                               make feel threatened      fear\n",
       "2                              dirty southern wanker     anger\n",
       "3  omg peyton good enough help u playoff dumbass ...  surprise\n",
       "4        need board create bit space name we’ll good       joy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918087f8-ca68-46f6-8337-80d8492c10a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i’m really sorry situation although love name ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king fan here good luck guy interesting game w...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i’m sorry hear friend it’s best likely didn’t ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>girlfriend weak well jump pathetic</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name towed line dark side cross something like...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  i’m really sorry situation although love name ...   sadness\n",
       "1  king fan here good luck guy interesting game w...       joy\n",
       "2  i’m sorry hear friend it’s best likely didn’t ...   sadness\n",
       "3                 girlfriend weak well jump pathetic   sadness\n",
       "4  name towed line dark side cross something like...     anger"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217dd51c-8814-454e-a4c2-cbeb48877eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i ve never sad life</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>could easily taken real camera legitimate sour...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wah mum people call bullshit can t ban go side...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>least name time gain confidence</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good want thrash liberal offspring world</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0                                i ve never sad life   sadness\n",
       "1  could easily taken real camera legitimate sour...       joy\n",
       "2  wah mum people call bullshit can t ban go side...     anger\n",
       "3                    least name time gain confidence       joy\n",
       "4           good want thrash liberal offspring world     anger"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6f5be9-b634-4215-874c-938adffecb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>      22829\n",
      "<class 'float'>        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['text'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea745403-fbae-435f-948c-e06201af919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>    22829\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[train_df['text'].apply(type) != float]\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "print(train_df['text'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f747d7f8-275f-4401-a809-85357f994edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>    2859\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df[test_df['text'].apply(type) != float]\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "print(test_df['text'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7844280-b200-4a29-b1f1-2bb5eeae1465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>    2852\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "val_df = val_df[val_df['text'].apply(type) != float]\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "print(val_df['text'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e9258-d70f-46e1-9aa8-caa13d73b749",
   "metadata": {},
   "source": [
    "### Data processing for LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c56541-e593-4af3-9e61-2c77f072fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['text']\n",
    "y_train = train_df['sentiment']\n",
    "\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['sentiment']\n",
    "\n",
    "X_val = val_df['text']\n",
    "y_val = val_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2fda88-9ca0-4da1-b46e-0c7de172717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "y_val = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53022996-013e-480f-9aa5-951694534114",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4b3d8c6-24cf-4859-aa04-a41c815f9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='UNK')\n",
    "tokenizer.fit_on_texts(pd.concat([X_train, X_test], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad23e9d0-e96b-43ee-b6d1-d871da9c0032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[66], [8991], [8992]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(X_train[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2cf4a93-8204-465b-a554-dde14cb8c6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 16864)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_matrix(X_train[0].split()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a65bf7ab-8e2e-4a09-9aad-7d424b75a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "sequences_val = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06a66fc9-b916-4a85-b5dc-b088aa1ddb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(text) for text in train_df['text']])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af0116a0-bc7e-4205-be7a-28e84347625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences_train, maxlen=max_len, truncating='pre')\n",
    "X_test = pad_sequences(sequences_test, maxlen=max_len, truncating='pre')\n",
    "X_val = pad_sequences(sequences_val, maxlen=max_len, truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9974ad9a-1459-48f5-87b4-60fd1f617bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.index_word) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1437e163-5e4f-43dc-ba18-31e0d702a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = vocab_size\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "embedding_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4b2ec9-fa2e-44f6-8f90-6b1ebb95dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd() \n",
    "glove_path = os.path.join(base_path, 'glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17a64ef0-ea92-4eec-99fd-a2f3f80de902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Glove embeddings\n",
    "with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # Split the line into word and coefficients\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e0cec21-1fcb-4016-9fe9-e6942558ace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 14543 words. Missed 2320 words.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "\n",
    "# Map the embeddings to your vocabulary\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_tokens:\n",
    "        continue  # Skip words beyond the vocabulary size\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words found in embedding index\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        # Words not found in embedding index\n",
    "        misses += 1\n",
    "\n",
    "print(f\"Converted {hits} words. Missed {misses} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e45b6d49-fc51-45d8-adb2-dab8b50a7646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victoria\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">145</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,686,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">145</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">731,136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">145</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m145\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m1,686,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m145\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m731,136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m145\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m656,384\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m394,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │           \u001b[38;5;34m1,542\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,469,702</span> (13.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,469,702\u001b[0m (13.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,783,302</span> (6.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,783,302\u001b[0m (6.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,686,400</span> (6.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,686,400\u001b[0m (6.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = y_train.shape[1]\n",
    "adam = Adam(learning_rate=0.005)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=X_train.shape[1], weights=[embedding_matrix], trainable=False))\n",
    "model.add(Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.build(\n",
    "    input_shape=(None, X_train.shape[1])\n",
    ")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2f9b7d6-9ae8-41e6-a4f1-ce14c71416ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (22829, 145)\n",
      "y_train shape: (22829, 6)\n"
     ]
    }
   ],
   "source": [
    "# Ensure both X_train and y_train have the same number of samples\n",
    "X_train = X_train[:len(y_train)]\n",
    "y_train = y_train[:len(X_train)]\n",
    "\n",
    "# Check again to confirm\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bec519d-ea04-44d8-85cb-e78ac1790147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks to prevent overfitting\n",
    "callbacks = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5415860-e18d-4eb8-9819-e2989dd95cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.4024 - loss: 1.4654 - val_accuracy: 0.5698 - val_loss: 1.1450\n",
      "Epoch 2/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5639 - loss: 1.1424 - val_accuracy: 0.5929 - val_loss: 1.0664\n",
      "Epoch 3/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.5988 - loss: 1.0600 - val_accuracy: 0.6048 - val_loss: 1.0466\n",
      "Epoch 4/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 2s/step - accuracy: 0.6153 - loss: 1.0038 - val_accuracy: 0.5799 - val_loss: 1.0877\n",
      "Epoch 5/30\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 3s/step - accuracy: 0.6077 - loss: 1.0256 - val_accuracy: 0.6346 - val_loss: 0.9911\n",
      "Epoch 6/30\n",
      "\u001b[1m85/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.6431 - loss: 0.9460"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=True,\n",
    "    batch_size=256,\n",
    "    epochs=30,\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720379c-111e-43a8-a7b4-b3a6293c3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_val, y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ba68d-afb1-40dc-b0e4-9fe00b188c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)\n",
    "y_pred = predicted.argmax(axis=-1)\n",
    "\n",
    "print(classification_report(le.transform(test_df['sentiment']), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e5c23-1c7e-420b-9da9-5bce1e000654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f694926-e1a1-445f-932f-d6427fbfd4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second model\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size, 100, input_length=X_train.shape[1], weights=[embedding_matrix], trainable=False))\n",
    "model2.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
    "model2.add(Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model2.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Compile the model\n",
    "adam = Adam(learning_rate=0.001)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dceb3eb-9c13-4caf-af6f-1bad2ab2d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model2.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=256,\n",
    "    epochs=30,\n",
    "    callbacks=[callbacks],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f9e80-3e11-4ab1-84eb-a6fb5c7408dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_val, y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfde7e-3643-47e0-a6f5-91622c3e1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model2.predict(X_test)\n",
    "y_pred = predicted.argmax(axis=-1)\n",
    "\n",
    "print(classification_report(le.transform(test_df['sentiment']), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a3e3f-0931-4985-9b4f-69ea7baebc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82904e24-8f6b-45f9-ba8e-7f499c6a7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"OMG! I just got a job offer today. I am so happy! Today is the best day\", #joy\n",
    "    \"I never make her separate from me because i don t ever want her to feel like i m ashamed with her\", #sadness\n",
    "    \"I cant walk into a shop anywhere where i do not feel uncomfortable\", #fear\n",
    "    \"I am feeling outraged it shows everywhere. I can not belive he did that to me. This makes me so angry and frustrated.\", #anger\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    print(\"Text: \" + text)\n",
    "    text = tokenizer.texts_to_sequences([text])\n",
    "    text = pad_sequences(text, maxlen=max_len, truncating='pre')\n",
    "    emotion = le.inverse_transform(np.argmax(model2.predict(text), axis=-1))[0]\n",
    "    \n",
    "    print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496081f-49a9-4fc1-8698-5fab9da5f4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

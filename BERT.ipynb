{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654b788a-1928-4241-a038-5071f416e12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\victoria\\anaconda3\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\victoria\\anaconda3\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: torch in c:\\users\\victoria\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\victoria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c3f3f0-a455-446b-a4f6-8651597b7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings, re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, TFBertModel\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPool1D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6afa45-1b3c-4f3f-a922-be90a055c68f",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1734d358-4864-480f-934a-c4944e047825",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('preprocessed_train.csv')\n",
    "test_df = pd.read_csv('preprocessed_test.csv')\n",
    "val_df = pd.read_csv('preprocessed_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a719bac-37c4-4dbe-a494-12fbfb4b63e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>    22829\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[train_df['text'].apply(type) != float]\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "print(train_df['text'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0b8805-816b-44b8-acde-7d5cb41e02f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>    2859\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df[test_df['text'].apply(type) != float]\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "print(test_df['text'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6714f8ff-0541-4359-91bc-6ffd377fd6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>    2852\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "val_df = val_df[val_df['text'].apply(type) != float]\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "print(val_df['text'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d2d2b6-63b8-4c67-97ef-cc330eb81393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fuck bayless isoing</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make feel threatened</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dirty southern wanker</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>omg peyton good enough help u playoff dumbass ...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>need board create bit space name we’ll good</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0                                fuck bayless isoing     anger\n",
       "1                               make feel threatened      fear\n",
       "2                              dirty southern wanker     anger\n",
       "3  omg peyton good enough help u playoff dumbass ...  surprise\n",
       "4        need board create bit space name we’ll good       joy"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acae514-3065-476a-9df8-51629fe94108",
   "metadata": {},
   "source": [
    "### Data Processing for model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0101a9ae-f5cf-4921-87d6-b65b2ae65491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "anger       7213\n",
       "fear        7213\n",
       "surprise    7213\n",
       "joy         7213\n",
       "sadness     7213\n",
       "disgust     7213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFRobertaModel, RobertaTokenizerFast\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "tokenizer_roberta = RobertaTokenizerFast.from_pretrained('cardiffnlp/twitter-roberta-base-emotion')\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "x_train, y_train = ros.fit_resample(np.array(train_df['text']).reshape(-1, 1), np.array(train_df['sentiment']).reshape(-1, 1))\n",
    "train_os = pd.DataFrame(list(zip([x[0] for x in x_train], y_train)), columns = ['text', 'sentiment'])\n",
    "train_os['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65a3e7e5-7415-4aec-8929-2fc5dfe33f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_os['text'].values\n",
    "y_train = train_os['sentiment'].values\n",
    "\n",
    "X_test = test_df['text'].values\n",
    "y_test = test_df['sentiment'].values\n",
    "\n",
    "X_valid = val_df['text'].values\n",
    "y_valid = val_df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ed44072-098a-4186-8da3-b62b51f8050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_train = OneHotEncoder().fit_transform(np.array(y_train).reshape(-1, 1)).toarray()\n",
    "y_valid = OneHotEncoder().fit_transform(np.array(y_valid).reshape(-1, 1)).toarray()\n",
    "y_test = OneHotEncoder().fit_transform(np.array(y_test).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69158588-455b-4b36-b34c-f0a86c4892d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in X_train:\n",
    "    tokens = tokenizer_roberta.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "max_length=np.max(token_lens)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "974eb452-c2e6-4d13-be26-6f95158d7834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted train_input_ids shape: torch.Size([43278, 43])\n",
      "Adjusted train_attention_mask shape: torch.Size([43278, 43])\n",
      "Adjusted train_labels shape: torch.Size([43278, 6])\n",
      "Adjusted test_input_ids shape: torch.Size([2859, 43])\n",
      "Adjusted test_attention_mask shape: torch.Size([2859, 43])\n",
      "Adjusted test_labels shape: torch.Size([2859, 6])\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Initialize DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_data(texts, labels, tokenizer, max_length=max_length):\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    labels = torch.tensor(labels)  # Ensure labels are numeric\n",
    "    return input_ids, attention_mask, labels\n",
    "\n",
    "# Tokenize train and test data\n",
    "train_input_ids, train_attention_mask, train_labels = tokenize_data(X_train, y_train, tokenizer)\n",
    "test_input_ids, test_attention_mask, test_labels = tokenize_data(X_test, y_test, tokenizer)\n",
    "\n",
    "# Ensure sizes match before creating datasets\n",
    "min_length = min(train_input_ids.size(0), train_attention_mask.size(0), train_labels.size(0))\n",
    "\n",
    "train_input_ids = train_input_ids[:min_length]\n",
    "train_attention_mask = train_attention_mask[:min_length]\n",
    "train_labels = train_labels[:min_length]\n",
    "\n",
    "# Repeat for test data\n",
    "min_length_test = min(test_input_ids.size(0), test_attention_mask.size(0), test_labels.size(0))\n",
    "\n",
    "test_input_ids = test_input_ids[:min_length_test]\n",
    "test_attention_mask = test_attention_mask[:min_length_test]\n",
    "test_labels = test_labels[:min_length_test]\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2571bbe-ba48-44a1-925e-0a74b6807d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode sentiments\n",
    "train_df[\"sentiment_encoded\"] = label_encoder.fit_transform(train_df[\"sentiment\"])\n",
    "test_df[\"sentiment_encoded\"] = label_encoder.transform(test_df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a3372a8-9ec5-4336-9075-cb04dcf1fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define a classifier using DistilBERT\n",
    "class CustomDistilBertClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(CustomDistilBertClassifier, self).__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.classifier = nn.Linear(self.distilbert.config.hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token's output\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits\n",
    "\n",
    "# Define the number of labels\n",
    "num_labels = len(train_df[\"sentiment_encoded\"].unique())\n",
    "\n",
    "# Initialize the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomDistilBertClassifier(num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfcb41ea-e350-4702-bee9-ded61d30bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac83850f-6f94-4885-9a70-066ca92e9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, optimizer, loss_fn, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d63b9b32-0c64-41be-9764-38baaeaabd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c56db-1316-4f12-a02c-e9f05ee87b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|█████████████████████████████████████████████████████████████████| 1353/1353 [2:06:07<00:00,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.7736795553630774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  56%|████████████████████████████████████▋                             | 751/1353 [57:53<1:52:50, 11.25s/it]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, optimizer, loss_fn, epochs=3)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01136fbd-b5b2-47b2-8d93-57cea9134cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
